<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Even - A super concise theme for Hugo</title>
    <link>http://localhost:1313/post/</link>
    <description>Recent content in Posts on Even - A super concise theme for Hugo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 06 Jun 2020 16:11:40 +0800</lastBuildDate>
    
	<atom:link href="http://localhost:1313/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>深入Spring源码 - 增强配置类</title>
      <link>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E5%A2%9E%E5%BC%BA%E9%85%8D%E7%BD%AE%E7%B1%BB/</link>
      <pubDate>Sat, 06 Jun 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E5%A2%9E%E5%BC%BA%E9%85%8D%E7%BD%AE%E7%B1%BB/</guid>
      <description>回顾两个知识点。 第一个知识点是—— 前面分析过，只要业务代码这样写，AppConfig类就有可能会进入到解析的逻辑： 1 2 3 AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(); ac.register(AppConfig.class); ac.refresh(); 有两种</description>
    </item>
    
    <item>
      <title>深入Spring源码 - 解析配置类</title>
      <link>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E8%A7%A3%E6%9E%90%E9%85%8D%E7%BD%AE%E7%B1%BB/</link>
      <pubDate>Sat, 06 Jun 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E8%A7%A3%E6%9E%90%E9%85%8D%E7%BD%AE%E7%B1%BB/</guid>
      <description>在前文中我们已经大致了解了Spring初始化的流程（主要针对AnnotationConfigApplicationContext）。主要流程</description>
    </item>
    
    <item>
      <title>深入Spring源码 - 初始化过程</title>
      <link>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Sun, 31 May 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/</guid>
      <description>初始化ApplicationContext有多种方式，比如如果配置了XML文件，则可以通过如下方式： 1 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&amp;#34;application.xml&amp;#34;); 如果是利用注解注入，则可以如</description>
    </item>
    
    <item>
      <title>深入Spring源码 - 自动注入的几种方式</title>
      <link>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%85%A5%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Mon, 25 May 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/spring/%E6%B7%B1%E5%85%A5spring%E6%BA%90%E7%A0%81-%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%85%A5%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid>
      <description>一个简单的例子 Spring有三种依赖注入方式，XML-based、Annotation-based和Java-based。三者之间没有冲突。</description>
    </item>
    
    <item>
      <title>深入Mybatis源码 - 一级缓存和二级缓存</title>
      <link>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-%E4%B8%80%E7%BA%A7%E7%BC%93%E5%AD%98%E5%92%8C%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/</link>
      <pubDate>Sun, 24 May 2020 13:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-%E4%B8%80%E7%BA%A7%E7%BC%93%E5%AD%98%E5%92%8C%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/</guid>
      <description>Mybatis提供了缓存机制，分为一级缓存和二级缓存。 一级缓存的作用域是单个SqlSession，如下： 1 2 3 4 5 6 7 8 9 10 SqlSession sqlSession = sqlSessionFactory.openSession(); DemoMapper mapper = sqlSession.getMapper(DemoMapper.class);</description>
    </item>
    
    <item>
      <title>深入Mybatis源码 - 分页原理以及插件的使用</title>
      <link>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-%E5%88%86%E9%A1%B5%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E6%8F%92%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 23 May 2020 17:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-%E5%88%86%E9%A1%B5%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E6%8F%92%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>在进行数据库查询并展示结果时，主要因为两个原因需要做分页： 1.给用户展示数据时，一次性显示太多对用户不友好。 2.数据量太大，全部加载的话会占</description>
    </item>
    
    <item>
      <title>深入Mybatis源码 - sql语句执行流程</title>
      <link>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-sql%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Sat, 23 May 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-sql%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</guid>
      <description>直接通过SqlSession对象增删改查 上文中介绍了SqlSessionFactory和SqlSession的初始化流程。在获得了SqlSe</description>
    </item>
    
    <item>
      <title>深入Mybatis源码 - 初始化流程</title>
      <link>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Sat, 23 May 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/mybatis/%E6%B7%B1%E5%85%A5mybatis%E6%BA%90%E7%A0%81-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B/</guid>
      <description>基本应用 在编写java程序时，与数据库连接会用到jdbc，但如果直接使用jdbc编程，会使得sql与java代码耦合，并且还需要自己手动实例</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 副本机制</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Sun, 10 May 2020 12:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6/</guid>
      <description>核心概念 副本、leader、follower 分布式系统常用副本(Replica)来实现数据的备份，进而实现容错、高可用等功能。在Kafka中</description>
    </item>
    
    <item>
      <title>深入Netty源码 - 客户端连接</title>
      <link>http://localhost:1313/post/netty/%E6%B7%B1%E5%85%A5netty%E6%BA%90%E7%A0%81-%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5/</link>
      <pubDate>Sat, 02 May 2020 12:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/netty/%E6%B7%B1%E5%85%A5netty%E6%BA%90%E7%A0%81-%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5/</guid>
      <description>接收网络连接事件 前文分析过，在服务端bind方法中，会启动一个新的线程，这个线程相当于就是Reactor模式中的主线程。其核心逻辑在run方</description>
    </item>
    
    <item>
      <title>深入Netty源码 - 服务端初始化</title>
      <link>http://localhost:1313/post/netty/%E6%B7%B1%E5%85%A5netty%E6%BA%90%E7%A0%81-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%88%9D%E5%A7%8B%E5%8C%96/</link>
      <pubDate>Fri, 01 May 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/netty/%E6%B7%B1%E5%85%A5netty%E6%BA%90%E7%A0%81-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%88%9D%E5%A7%8B%E5%8C%96/</guid>
      <description>上文说到一个Netty服务端的代码一般编写成如下形式： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class NettyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup=new NioEventLoopGroup(1); EventLoopGroup workerGroup=new</description>
    </item>
    
    <item>
      <title>深入Netty源码 - 创建NioEventLoopGroup</title>
      <link>http://localhost:1313/post/netty/%E6%B7%B1%E5%85%A5netty%E6%BA%90%E7%A0%81-%E5%88%9B%E5%BB%BAnioeventloopgroup/</link>
      <pubDate>Fri, 01 May 2020 12:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/netty/%E6%B7%B1%E5%85%A5netty%E6%BA%90%E7%A0%81-%E5%88%9B%E5%BB%BAnioeventloopgroup/</guid>
      <description>Netty的服务端代码通常都会编写成如下形式： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class NettyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup=new NioEventLoopGroup(1); EventLoopGroup workerGroup=new NioEventLoopGroup(); ServerBootstrap serverBootstrap=new ServerBootstrap();</description>
    </item>
    
    <item>
      <title>Java基础 - 基于JDK中的Future实现异步编程</title>
      <link>http://localhost:1313/post/java%E5%9F%BA%E7%A1%80/java%E5%9F%BA%E7%A1%80-%E5%9F%BA%E4%BA%8Ejdk%E4%B8%AD%E7%9A%84future%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Tue, 28 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/java%E5%9F%BA%E7%A1%80/java%E5%9F%BA%E7%A1%80-%E5%9F%BA%E4%BA%8Ejdk%E4%B8%AD%E7%9A%84future%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</guid>
      <description>上文讲到说用用线程实现异步编程，有两个问题比较突出： 1.实际场景中任务个数非常多，如果每次都创建一个新的线程则资源消耗太大。 2.获取一个线程</description>
    </item>
    
    <item>
      <title>Java基础 - 使用线程和线程池实现异步编程</title>
      <link>http://localhost:1313/post/java%E5%9F%BA%E7%A1%80/java%E5%9F%BA%E7%A1%80-%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Tue, 28 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/java%E5%9F%BA%E7%A1%80/java%E5%9F%BA%E7%A1%80-%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</guid>
      <description>在I/O模型中，有两对概念经常让人混淆——阻塞和非阻塞、同步和异步。 在不同的语境下，这些概念有着不同的内涵。其中一种比较严谨的描述来自UNI</description>
    </item>
    
    <item>
      <title>历史碎片 - 马基雅维利与美第奇家族</title>
      <link>http://localhost:1313/post/%E5%8E%86%E5%8F%B2%E7%A2%8E%E7%89%87/%E5%8E%86%E5%8F%B2%E7%A2%8E%E7%89%87-%E9%A9%AC%E5%9F%BA%E9%9B%85%E7%BB%B4%E5%88%A9%E4%B8%8E%E7%BE%8E%E7%AC%AC%E5%A5%87%E5%AE%B6%E6%97%8F/</link>
      <pubDate>Mon, 27 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%8E%86%E5%8F%B2%E7%A2%8E%E7%89%87/%E5%8E%86%E5%8F%B2%E7%A2%8E%E7%89%87-%E9%A9%AC%E5%9F%BA%E9%9B%85%E7%BB%B4%E5%88%A9%E4%B8%8E%E7%BE%8E%E7%AC%AC%E5%A5%87%E5%AE%B6%E6%97%8F/</guid>
      <description>玩过《刺客信条2》的朋友一定知道，在游戏中马基雅维利是刺客意大利兄弟会的一名导师，也是佛罗伦萨共和国的一名政客、外交官，同时还自己招兵买马，</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（LogManager）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8logmanager/</link>
      <pubDate>Thu, 23 Apr 2020 11:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8logmanager/</guid>
      <description>前文已经了解了Kafka Server端写日志的整个流程，熟悉了Log、LogSegment等概念以及代码中对它们的使用，不过并没有提及这些对</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（Server端消息的迭代）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8server%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</link>
      <pubDate>Wed, 22 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8server%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</guid>
      <description>前文分析了Consumer端消息的迭代。Server端也需要迭代，因为需要对消息进行验证、分配offset（因为生产者带过来的只有相对off</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（Consumer端消息的迭代）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8consumer%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</link>
      <pubDate>Tue, 21 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8consumer%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</guid>
      <description>前文讲到生产者生产的消息如果经过压缩，则会形成嵌套的结构： 那么自然而然，要对这个消息进行处理，就需要迭代地进行处理。 本文分析Consumer</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（日志写入的整体流程）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E7%9A%84%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Mon, 20 Apr 2020 17:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E7%9A%84%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B/</guid>
      <description>基本概念 生产者将消息发送到服务端后，服务端要把消息存储到本地日志文件。 Kafka用Log代表一个TopicPartition的日志。但Log</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（消息的格式）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%B6%88%E6%81%AF%E7%9A%84%E6%A0%BC%E5%BC%8F/</link>
      <pubDate>Mon, 20 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%B6%88%E6%81%AF%E7%9A%84%E6%A0%BC%E5%BC%8F/</guid>
      <description>在分析Producer端生产消息的流程一文中，我们知道了生产者会先构造一个RecordBatch，然后将消息一条条放入其中；当一个Recor</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的定时任务（定时任务的执行）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%89%A7%E8%A1%8C/</link>
      <pubDate>Mon, 20 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%89%A7%E8%A1%8C/</guid>
      <description>生产者给服务端发送消息后，服务端不会立刻返回响应，而是创建一个DelayedProduce对象做延迟操作。消费者那边的情况与此类似。 前文已经</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的定时任务（时间轮的工作原理）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E6%97%B6%E9%97%B4%E8%BD%AE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 19 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E6%97%B6%E9%97%B4%E8%BD%AE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</guid>
      <description>时间轮的整体结构 如上图所示，时间轮可以描绘为这样一个环形结构。任务存放在每个单元格中。不过并不是一个单元格就对应一个任务，而是一个单元格对应</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的定时任务（JDK Timer的实现原理）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1jdk-timer%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 19 Apr 2020 15:11:30 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1jdk-timer%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</guid>
      <description>Kafka Server端用一个组件（即一个类）叫做DelayedOperationPurgatory，负责定时任务的执行。而我们知道JDK自带了定时</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的网络层（Kafka的实现）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82kafka%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Wed, 15 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82kafka%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
      <description>网络层 Kafka Server端的网络层使用的就是多线程多Selector的Reactor模式。 Kafka Server端的启动在KafkaServer类的st</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的网络层（Reactor模式介绍）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82reactor%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Wed, 15 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82reactor%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/</guid>
      <description>Reactor模式是一种事件驱动模式，常见于IO模型中，Java NIO提供了实现该模式的API。本文略去概念的介绍，直接从代码学习。 单线程R</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Consumer端接收数据全流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-consumer%E7%AB%AF%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Tue, 31 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-consumer%E7%AB%AF%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</guid>
      <description>一段比较简单的业务代码通常包含下面4步： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public static void main(String[] args) { ...... // 1.构造KafkaConsumer对象</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Producer端发送数据全流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-producer%E7%AB%AF%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Mon, 30 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-producer%E7%AB%AF%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</guid>
      <description>学习Kafka源码简单来说可以分为三部分来学——Producer端、Consumer端和Server端。其中Producer端和Consum</description>
    </item>
    
    <item>
      <title>深入浅出SVM （四）——解决非线性问题</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E5%9B%9B%E8%A7%A3%E5%86%B3%E9%9D%9E%E7%BA%BF%E6%80%A7%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 28 Mar 2020 18:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E5%9B%9B%E8%A7%A3%E5%86%B3%E9%9D%9E%E7%BA%BF%E6%80%A7%E9%97%AE%E9%A2%98/</guid>
      <description>无论是硬间隔还是软间隔，得到的决策边界都是线性的。如果样本完全线性不可分，则主要有两种方式来解决这一问题： 1.改用非线性分类器，如神经网络。</description>
    </item>
    
    <item>
      <title>深入浅出SVM （三）——对偶问题</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E4%B8%89%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 28 Mar 2020 17:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E4%B8%89%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/</guid>
      <description>很多问题都有自己的对偶问题。转换成对偶问题一般有两个好处。 1.计算上更加简单。 2.对偶形式会产生一些特殊的性质。 对于SVM来说，将原始问题转</description>
    </item>
    
    <item>
      <title>深入浅出SVM （二）——硬间隔与软间隔</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E4%BA%8C%E7%A1%AC%E9%97%B4%E9%9A%94%E4%B8%8E%E8%BD%AF%E9%97%B4%E9%9A%94/</link>
      <pubDate>Sat, 28 Mar 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E4%BA%8C%E7%A1%AC%E9%97%B4%E9%9A%94%E4%B8%8E%E8%BD%AF%E9%97%B4%E9%9A%94/</guid>
      <description>从硬间隔到软间隔 在上一小节中，我们给出了SVM的基本型： \[\large min_{w,b}\frac{1}{2}||w||^2 \\ \large s.t. \ \ \ y_i(w^Tx_i+b)\geq1, \ \ \ \ \ \ \ i=1,2,\dots,m\] 解决的是如下图这样的分类问题： 这是一种非常理想的情</description>
    </item>
    
    <item>
      <title>深入浅出SVM （一）——SVM的基本思想</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E4%B8%80svm%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/</link>
      <pubDate>Sat, 28 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAsvm-%E4%B8%80svm%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/</guid>
      <description>如下图所示，给定样本后，如果用线性分类器给样本分类，可以有无数个决策边界。 有很多模型都属于线性分类器，如逻辑回归等。但是在优化逻辑回归模型的</description>
    </item>
    
    <item>
      <title>深入Flink源码 - 并行度与最大并行度</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%B9%B6%E8%A1%8C%E5%BA%A6/</link>
      <pubDate>Fri, 20 Mar 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%B9%B6%E8%A1%8C%E5%BA%A6/</guid>
      <description>Flink关于并行度有两个概念——并行度与最大并行度。在做业务代码的开发时，算子后面可以跟setMaxParallelism或者setPar</description>
    </item>
    
    <item>
      <title>深入Flink源码 - Checkpoint状态恢复流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Fri, 20 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B/</guid>
      <description>flink本身有重启机制，本文分析的是通过flink run -s 命令恢复任务的流程。 flink checkpoint文件是自描述的，_metadata文件保存</description>
    </item>
    
    <item>
      <title>深入Flink源码 - Checkpoint文件的写入流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Wed, 18 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</guid>
      <description>在开启了Flink的checkpoint机制后，每一次成功地进行checkpoint都可以在checkpoint的目录下看到一个新的检查点目</description>
    </item>
    
    <item>
      <title>深入Flink源码 - FlinkKafkaConsumer如何维护和恢复offset</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-flinkkafkaconsumer%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4%E5%92%8C%E6%81%A2%E5%A4%8Doffset/</link>
      <pubDate>Sun, 15 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-flinkkafkaconsumer%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4%E5%92%8C%E6%81%A2%E5%A4%8Doffset/</guid>
      <description>问题的由来 在利用Flink做业务开发时，经常会让Flink从Kafka读取数据进行消费。初始化的代码通常遵循如下范式： 1 2 3 4 5 6 7 8 9 10 11</description>
    </item>
    
    <item>
      <title>深入浅出逻辑回归（四）——从最大熵模型到逻辑回归模型</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9B%9B%E4%BB%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E5%88%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Tue, 31 Dec 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9B%9B%E4%BB%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E5%88%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</guid>
      <description>最大熵模型 最大熵模型是一种更加“高屋建瓴”的统计模型。它由最大熵原理推导而来。我们可以认为逻辑回归模型是它的一种特例，稍后我们会做相关推导。</description>
    </item>
    
    <item>
      <title>深入浅出逻辑回归（三）——模型参数估计</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%89%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</link>
      <pubDate>Mon, 30 Dec 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%89%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</guid>
      <description>用 MLE 估计模型参数 对于给定的样本集 \(D=\{(x^{(1)},y^{(1)}),\ (x^{(2)},y^{(2)}),\ \cdots\ ,\ (x^{(N)},y^{(N)})\}\) ，其中 $y^{(i)}\in {0,1}$ 。为了简化，我们令 $P(Y=1|x)=\frac{exp(w\cdot x)}{1+exp(w\cdot x)}=\pi(x),\ P(Y=0|x)=1-\pi(x)$ 。 根据 MLE，我们写出似然函数： \[\large \prod^{N}_{i=1}[\pi(x^{(i)})]^{y^{(i)}}[1-\pi(x^{(i)})]^{1-y^{(i)}}\] 对数似然函数为： \[\large \begin{align}L(w)&amp;=\sum^N_{i=1}[y^{(i)}\log(\pi(x^{(i)}))+(1-y^{(i)})\log(1-\pi(x^{(i)}))]\\&amp;=\sum^N_{i=1}[y^{(i)}\log(\frac{\pi(x^{(i)})}{1-\pi(x^{(i)})})+\log(1-\pi(x^{(i)}))]\\&amp;=\sum^N_{i=1}[y^{(i)}(w\cdot x^{(i)})-\log(1+exp(w\cdot x^{(i)}))]\end{align}\] 然</description>
    </item>
    
    <item>
      <title>深入浅出逻辑回归（二）——逻辑回归是线性分类器吗？</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%98%AF%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8%E5%90%97/</link>
      <pubDate>Sun, 29 Dec 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%98%AF%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8%E5%90%97/</guid>
      <description>上一小节我们得到逻辑回归模型的表达式为： \[\large P(Y=1|x)=\frac{\exp (w\cdot x)}{1+\exp (w\cdot x)}\] 很显然这是一个非线性的函数。它长成这个样子： 看不出逻辑回归模型是线性模型的证据。 逻辑回归</description>
    </item>
    
    <item>
      <title>深入浅出逻辑回归（一）——逻辑回归模型长什么样</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%80%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7/</link>
      <pubDate>Sat, 28 Dec 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%80%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7/</guid>
      <description>理解逻辑回归模型有多种视角，从不同的视角可以分别看到逻辑回归与其它模型之间的联系与区别。这里还是先从线性回归模型展开，得到逻辑回归模型的公式</description>
    </item>
    
    <item>
      <title>深入浅出朴素贝叶斯（三）——期望风险最小化视角</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%89%E6%9C%9F%E6%9C%9B%E9%A3%8E%E9%99%A9%E6%9C%80%E5%B0%8F%E5%8C%96%E8%A7%86%E8%A7%92/</link>
      <pubDate>Thu, 05 Dec 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%89%E6%9C%9F%E6%9C%9B%E9%A3%8E%E9%99%A9%E6%9C%80%E5%B0%8F%E5%8C%96%E8%A7%86%E8%A7%92/</guid>
      <description>当我们算出了各个需要的频率后，就可以计算出 $Pr(Category|Document)$ 的相对值（之所以说是相对值，是因为我们没有计算 $Pr(Document)$ ），然后选择 $Pr$ 最大的那个分类。这种做法不仅仅是一</description>
    </item>
    
    <item>
      <title>深入浅出朴素贝叶斯（二）——重新认识朴素贝叶斯</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BA%8C%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</link>
      <pubDate>Wed, 04 Dec 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BA%8C%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</guid>
      <description>文档的表示方式 在上一节中，我们先计算了每个单词的 $Pr(Word|Category)$ ，将它们相乘得到 $Pr(Document|Category)$ ，然后计算出 $Pr(Category)$ ，算出 $Pr(Document|Category)\times Pr(Category)$ ，通过每个类别的对比就得到了文档的分类。 最后我们</description>
    </item>
    
    <item>
      <title>深入浅出朴素贝叶斯（一）——从垃圾邮件过滤开始</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%80%E4%BB%8E%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E5%88%86%E7%B1%BB%E5%BC%80%E5%A7%8B/</link>
      <pubDate>Tue, 03 Dec 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%80%E4%BB%8E%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E5%88%86%E7%B1%BB%E5%BC%80%E5%A7%8B/</guid>
      <description>问题的由来 随着电子邮件的普及和超低的发送成本，我们受到越来越多垃圾邮件的困扰，导致真正有价值的邮件被淹没。垃圾邮件的过滤是机器学习非常早期的</description>
    </item>
    
    <item>
      <title>深入浅出线性回归（五）——贝叶斯视角</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BA%94%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%A7%86%E8%A7%92/</link>
      <pubDate>Thu, 14 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BA%94%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%A7%86%E8%A7%92/</guid>
      <description>频率派和贝叶斯派 在讨论统计与概率时，基于不同的出发点和世界观，衍生出了频率派和贝叶斯派两种流派。简单地说，频率派认为参数是一个固定的值，只不</description>
    </item>
    
    <item>
      <title>深入浅出线性回归（四）——最小二乘法的几何解释</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%9B%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%9A%84%E5%87%A0%E4%BD%95%E8%A7%A3%E9%87%8A/</link>
      <pubDate>Wed, 13 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%9B%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%9A%84%E5%87%A0%E4%BD%95%E8%A7%A3%E9%87%8A/</guid>
      <description>回顾第一节的内容。 \[\large J(\theta)=\frac{1}{2}\sum_{i=1}^n(y^{(i)}-\theta^Tx^{(i)})^2\] 利用最小二乘法，我们得到了解析解：\(\theta=(X^TX)^{-1}X^TY\) 。 我们当时的解释是，用真实值和估</description>
    </item>
    
    <item>
      <title>深入浅出线性回归（三）——正则化</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%89%E6%AD%A3%E5%88%99%E5%8C%96/</link>
      <pubDate>Tue, 12 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%89%E6%AD%A3%E5%88%99%E5%8C%96/</guid>
      <description>什么是正则化 很多文章都说，为了防止过拟合，我们可以在损失函数后面添加一个正则项。一般有两种正则化： \[\large L1正则化: J(\theta)=\frac{1}{2}\sum_{i=1}^n(y^{(i)}-\theta^Tx^{(i)})^2+\alpha||\theta||_1\] \[\large L2正则化: J(\theta)=\frac{1}{2}\sum_{i=1}^n(y^{(i)}-\theta^Tx^{(i)})^2+\alpha||\theta||_2^2\] 其中\(|</description>
    </item>
    
    <item>
      <title>深入浅出线性回归（二）——极大似然估计</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BA%8C%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</link>
      <pubDate>Mon, 11 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BA%8C%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</guid>
      <description>上一节中有这样一个式子： \[\large J(\theta)=\frac{1}{2}\sum_{i=1}^n(y^{(i)}-\theta^Tx^{(i)})^2\] 这个函数叫做损失函数。我们要找到 $\theta$ 使损失函数达到最小值。用 \((y^{(i)}-\theta^Tx^{(i)})^2\) 表示真实值和估计值之间的距离，然后使所有样本的这个距</description>
    </item>
    
    <item>
      <title>深入浅出线性回归（一）——解析解与梯度下降法</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%80%E8%A7%A3%E6%9E%90%E8%A7%A3%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</link>
      <pubDate>Sun, 10 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%80%E8%A7%A3%E6%9E%90%E8%A7%A3%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</guid>
      <description>线性回归简介 我们手头有一堆样本的输入 \(X=\begin{pmatrix}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\\vdots &amp; \vdots &amp; &amp; \vdots \\ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end{pmatrix}$ 和输出 $Y=\begin{pmatrix}y_1\\y_2\\\vdots\\y_n\end{pmatrix}\) ，想要找到一个线性模型 \(f(X)=X\theta\) 描绘它们之间</description>
    </item>
    
    <item>
      <title>深入浅出 PCA（六）——奇异值分解（SVD）视角</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E5%85%AD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3svd/</link>
      <pubDate>Sat, 09 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E5%85%AD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3svd/</guid>
      <description>说到降维，可能有些同学还听过 SVD，但也许没有理顺它和 PCA 的关系。严格来说， SVD 与降维没有直接关系，它只是每个矩阵都有的性质。即任意一个矩阵 $A$ 都</description>
    </item>
    
    <item>
      <title>深入浅出 PCA（五）——最小重构代价视角</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%BA%94%E6%9C%80%E5%B0%8F%E9%87%8D%E6%9E%84%E4%BB%A3%E4%BB%B7%E8%A7%86%E8%A7%92/</link>
      <pubDate>Fri, 08 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%BA%94%E6%9C%80%E5%B0%8F%E9%87%8D%E6%9E%84%E4%BB%A3%E4%BB%B7%E8%A7%86%E8%A7%92/</guid>
      <description>上一小节我们通过最大投影方差视角，印证了取出对角化后的协方差矩阵中最大特征值对应的特征向量的合理性。但还有一个问题没有回答，就是降维以后信息</description>
    </item>
    
    <item>
      <title>深入浅出 PCA（四）——最大投影方差视角</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E5%9B%9B%E6%9C%80%E5%A4%A7%E6%8A%95%E5%BD%B1%E6%96%B9%E5%B7%AE%E8%A7%86%E8%A7%92/</link>
      <pubDate>Thu, 07 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E5%9B%9B%E6%9C%80%E5%A4%A7%E6%8A%95%E5%BD%B1%E6%96%B9%E5%B7%AE%E8%A7%86%E8%A7%92/</guid>
      <description>我们已经知道了 PCA 的具体步骤。先求出样本矩阵的协方差矩阵，将其对角化，对角元素从大到小排列，按需求选出最大的几个特征值，找出对应的特征向量，组</description>
    </item>
    
    <item>
      <title>深入浅出 PCA（三）——协方差矩阵</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%B8%89%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/</link>
      <pubDate>Wed, 06 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%B8%89%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/</guid>
      <description>什么是协方差 对于样本的每一维，我们都可以算出它的平均值 $\mu$ 和方差 $\sigma^2$ 。用期望表示的话，公式如下（用 $x$ 表示样本在这一维的取值）： \[\begin{equation}\mu=E[x]\\\sigma^2=E[(x-E[x])^2]\end{equation}\] 这是最常见的两个</description>
    </item>
    
    <item>
      <title>深入浅出 PCA（二）——矩阵对角化</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%BA%8C%E7%9F%A9%E9%98%B5%E5%AF%B9%E8%A7%92%E5%8C%96/</link>
      <pubDate>Tue, 05 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%BA%8C%E7%9F%A9%E9%98%B5%E5%AF%B9%E8%A7%92%E5%8C%96/</guid>
      <description>什么是 PCA PCA 就是利用正交变换，来对一系列可能相关的变量的观测值进行线性变换，从而投影为一系列线性不相关变量的值，这些不相关变量称为主成分（Pr</description>
    </item>
    
    <item>
      <title>深入浅出 PCA（一）——降维</title>
      <link>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%B8%80%E9%99%8D%E7%BB%B4/</link>
      <pubDate>Mon, 04 Nov 2019 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pca/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-pca%E4%B8%80%E9%99%8D%E7%BB%B4/</guid>
      <description>简介 PCA（PrincipalComponents Analysis）即主成分分析，是最常用的降维方法。 我们先不用去理解什么是主成分分析，更不</description>
    </item>
    
  </channel>
</rss>
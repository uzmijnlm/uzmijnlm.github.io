<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>大数据 on Even - A super concise theme for Hugo</title>
    <link>http://localhost:1313/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link>
    <description>Recent content in 大数据 on Even - A super concise theme for Hugo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 15 Apr 2020 16:11:40 +0800</lastBuildDate>
    
	<atom:link href="http://localhost:1313/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的网络层（Kafka的实现）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82kafka%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Wed, 15 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82kafka%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
      <description>网络层 Kafka Server端的网络层使用的就是多线程多Selector的Reactor模式。 Kafka Server端的启动在KafkaServer类的st</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的网络层（Reactor模式介绍）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82reactor%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Wed, 15 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82reactor%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/</guid>
      <description>Reactor模式是一种事件驱动模式，常见于IO模型中，Java NIO提供了实现该模式的API。本文略去概念的介绍，直接从代码学习。 单线程R</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Consumer端接收数据全流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-consumer%E7%AB%AF%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Tue, 31 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-consumer%E7%AB%AF%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</guid>
      <description>一段比较简单的业务代码通常包含下面4步： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public static void main(String[] args) { ...... // 1.构造KafkaConsumer对象</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Producer端发送数据全流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-producer%E7%AB%AF%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Mon, 30 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-producer%E7%AB%AF%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</guid>
      <description>学习Kafka源码简单来说可以分为三部分来学——Producer端、Consumer端和Server端。其中Producer端和Consum</description>
    </item>
    
    <item>
      <title>深入Flink源码 - 并行度与最大并行度</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%B9%B6%E8%A1%8C%E5%BA%A6/</link>
      <pubDate>Fri, 20 Mar 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%B9%B6%E8%A1%8C%E5%BA%A6/</guid>
      <description>Flink关于并行度有两个概念——并行度与最大并行度。在做业务代码的开发时，算子后面可以跟setMaxParallelism或者setPar</description>
    </item>
    
    <item>
      <title>深入Flink源码 - Checkpoint状态恢复流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Fri, 20 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B/</guid>
      <description>flink本身有重启机制，本文分析的是通过flink run -s 命令恢复任务的流程。 flink checkpoint文件是自描述的，_metadata文件保存</description>
    </item>
    
    <item>
      <title>深入Flink源码 - Checkpoint文件的写入流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Wed, 18 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</guid>
      <description>在开启了Flink的checkpoint机制后，每一次成功地进行checkpoint都可以在checkpoint的目录下看到一个新的检查点目</description>
    </item>
    
    <item>
      <title>深入Flink源码 - FlinkKafkaConsumer如何维护和恢复offset</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-flinkkafkaconsumer%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4%E5%92%8C%E6%81%A2%E5%A4%8Doffset/</link>
      <pubDate>Sun, 15 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-flinkkafkaconsumer%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4%E5%92%8C%E6%81%A2%E5%A4%8Doffset/</guid>
      <description>问题的由来 在利用Flink做业务开发时，经常会让Flink从Kafka读取数据进行消费。初始化的代码通常遵循如下范式： 1 2 3 4 5 6 7 8 9 10 11</description>
    </item>
    
  </channel>
</rss>
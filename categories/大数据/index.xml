<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>大数据 on Even - A super concise theme for Hugo</title>
    <link>http://localhost:1313/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link>
    <description>Recent content in 大数据 on Even - A super concise theme for Hugo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 23 Apr 2020 11:11:40 +0800</lastBuildDate>
    
	<atom:link href="http://localhost:1313/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>深入Kafka源码 - 日志存储（LogManager）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8logmanager/</link>
      <pubDate>Thu, 23 Apr 2020 11:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8logmanager/</guid>
      <description>前文已经了解了Kafka Server端写日志的整个流程，熟悉了Log、LogSegment等概念以及代码中对它们的使用，不过并没有提及这些对</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（Server端消息的迭代）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8server%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</link>
      <pubDate>Wed, 22 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8server%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</guid>
      <description>前文分析了Consumer端消息的迭代。Server端也需要迭代，因为需要对消息进行验证、分配offset（因为生产者带过来的只有相对off</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（Consumer端消息的迭代）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8consumer%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</link>
      <pubDate>Tue, 21 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8consumer%E7%AB%AF%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%AD%E4%BB%A3/</guid>
      <description>前文讲到生产者生产的消息如果经过压缩，则会形成嵌套的结构： 那么自然而然，要对这个消息进行处理，就需要迭代地进行处理。 本文分析Consumer</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（日志写入的整体流程）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E7%9A%84%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Mon, 20 Apr 2020 17:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E7%9A%84%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B/</guid>
      <description>基本概念 生产者将消息发送到服务端后，服务端要把消息存储到本地日志文件。 Kafka用Log代表一个TopicPartition的日志。但Log</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - 日志存储（消息的格式）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%B6%88%E6%81%AF%E7%9A%84%E6%A0%BC%E5%BC%8F/</link>
      <pubDate>Mon, 20 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%B6%88%E6%81%AF%E7%9A%84%E6%A0%BC%E5%BC%8F/</guid>
      <description>在分析Producer端生产消息的流程一文中，我们知道了生产者会先构造一个RecordBatch，然后将消息一条条放入其中；当一个Recor</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的定时任务（定时任务的执行）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%89%A7%E8%A1%8C/</link>
      <pubDate>Mon, 20 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%89%A7%E8%A1%8C/</guid>
      <description>生产者给服务端发送消息后，服务端不会立刻返回响应，而是创建一个DelayedProduce对象做延迟操作。消费者那边的情况与此类似。 前文已经</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的定时任务（时间轮的工作原理）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E6%97%B6%E9%97%B4%E8%BD%AE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 19 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E6%97%B6%E9%97%B4%E8%BD%AE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</guid>
      <description>时间轮的整体结构 如上图所示，时间轮可以描绘为这样一个环形结构。任务存放在每个单元格中。不过并不是一个单元格就对应一个任务，而是一个单元格对应</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的定时任务（JDK Timer的实现原理）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1jdk-timer%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 19 Apr 2020 15:11:30 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1jdk-timer%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</guid>
      <description>Kafka Server端用一个组件（即一个类）叫做DelayedOperationPurgatory，负责定时任务的执行。而我们知道JDK自带了定时</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的网络层（Kafka的实现）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82kafka%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Wed, 15 Apr 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82kafka%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
      <description>网络层 Kafka Server端的网络层使用的就是多线程多Selector的Reactor模式。 Kafka Server端的启动在KafkaServer类的st</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Kafka Server端的网络层（Reactor模式介绍）</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82reactor%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Wed, 15 Apr 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-kafka-server%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82reactor%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/</guid>
      <description>Reactor模式是一种事件驱动模式，常见于IO模型中，Java NIO提供了实现该模式的API。本文略去概念的介绍，直接从代码学习。 单线程R</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Consumer端接收数据全流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-consumer%E7%AB%AF%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Tue, 31 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-consumer%E7%AB%AF%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</guid>
      <description>一段比较简单的业务代码通常包含下面4步： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public static void main(String[] args) { ...... // 1.构造KafkaConsumer对象</description>
    </item>
    
    <item>
      <title>深入Kafka源码 - Producer端发送数据全流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-producer%E7%AB%AF%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Mon, 30 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/%E6%B7%B1%E5%85%A5kafka%E6%BA%90%E7%A0%81-producer%E7%AB%AF%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%85%A8%E6%B5%81%E7%A8%8B/</guid>
      <description>学习Kafka源码简单来说可以分为三部分来学——Producer端、Consumer端和Server端。其中Producer端和Consum</description>
    </item>
    
    <item>
      <title>深入Flink源码 - 并行度与最大并行度</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%B9%B6%E8%A1%8C%E5%BA%A6/</link>
      <pubDate>Fri, 20 Mar 2020 16:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%B9%B6%E8%A1%8C%E5%BA%A6/</guid>
      <description>Flink关于并行度有两个概念——并行度与最大并行度。在做业务代码的开发时，算子后面可以跟setMaxParallelism或者setPar</description>
    </item>
    
    <item>
      <title>深入Flink源码 - Checkpoint状态恢复流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Fri, 20 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B/</guid>
      <description>flink本身有重启机制，本文分析的是通过flink run -s 命令恢复任务的流程。 flink checkpoint文件是自描述的，_metadata文件保存</description>
    </item>
    
    <item>
      <title>深入Flink源码 - Checkpoint文件的写入流程</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Wed, 18 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-checkpoint%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</guid>
      <description>在开启了Flink的checkpoint机制后，每一次成功地进行checkpoint都可以在checkpoint的目录下看到一个新的检查点目</description>
    </item>
    
    <item>
      <title>深入Flink源码 - FlinkKafkaConsumer如何维护和恢复offset</title>
      <link>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-flinkkafkaconsumer%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4%E5%92%8C%E6%81%A2%E5%A4%8Doffset/</link>
      <pubDate>Sun, 15 Mar 2020 15:11:40 +0800</pubDate>
      
      <guid>http://localhost:1313/post/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/%E6%B7%B1%E5%85%A5flink%E6%BA%90%E7%A0%81-flinkkafkaconsumer%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4%E5%92%8C%E6%81%A2%E5%A4%8Doffset/</guid>
      <description>问题的由来 在利用Flink做业务开发时，经常会让Flink从Kafka读取数据进行消费。初始化的代码通常遵循如下范式： 1 2 3 4 5 6 7 8 9 10 11</description>
    </item>
    
  </channel>
</rss>